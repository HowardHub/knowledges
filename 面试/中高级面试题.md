##### 一、如何不用xxl-job写一个定时任务，实现手动和定时执行的功能，并且如何保证并发问题？

Timer，

```txt
1.首先Timer对调度的支持是基于绝对时间的，而不是相对时间，所以它对系统时间的改变非常敏感。
2.其次Timer线程是不会捕获异常的，如果TimerTask抛出的了未检查异常则会导致Timer线程终止，
  同时Timer也不会重新恢复线程的执行，它会错误的认为整个Timer线程都会取消。
```

ScheduledExecutorService







##### 二、如果在controller层调用了两个加了事务的service方法，会不会有什么问题？如何保证日志记录（出现回滚也要记录日志）

```java
	// UserServiceImpl的两个事务方法
	@Override
    @Transactional(rollbackFor = Exception.class)
    public Void updateUserById1() {
        User user = new User();
        user.setId(1L);
        user.setName("zhansan");
        user.setPassword("456");
        this.baseMapper.updateById(user);
        return null;
    }

    @Override
    @Transactional(rollbackFor = Exception.class)
    public Void updateUserById2() {
        int i=1/0; // 让方法二执行失败，看看方法1是否回滚
        return null;
    }
```

```java
// controller层的验证
@ApiOperation("事务验证")
@GetMapping("/transaction/check")
private String transactionCheck(){
    userService.updateUserById1();
    userService.updateUserById2();
    return "OK";
}
```

会出现问题，无法保证事务回滚。**因为spring的事务是基于aop实现的，aop的底层又是动态代理，调用service的不同方法会生成不同的代理对象,所以不能保证一个事务。**

解决方案：

**利用AopContext.currentProxy()，拿到当前线程的代理对象来请求被调用类的方法，被调用的方法才会被代理**

```java
	@ApiOperation("事务验证")
    @GetMapping("/transaction/check")
    private String transactionCheck(){
        userService.updateUserById1();
        ((IUserService) AopContext.currentProxy()).updateUserById2(); 
        return "OK";
    }
```





如何保证日志记录？不管事务有没有回滚
 1、@Async注解设置异步执行，轻量切线程脱离事务控制，能满足方法中特殊场景数值的记载。被调用方法的实际执行是交给Spring的TaskExecutor来完成。可以把日志方法抽象到加这个注解的方法中，然后再来进行调用。
 2、@Transactional(propagation = Propagation.NOT_SUPPORTED) ，另起事务的方式操作，本质上和方法一是一个思路，另起线程，但操作范围大了，事务链的控制也比较繁琐。
 3、aop方式 ，有点是在可以指定范围内的类 方法批量的进行切面拦截处理，在进入前 结束后 还有所谓的环绕等，进行各种操作。操作的面更广，但是有个缺点是绕不开的，如果你要取到方法中特殊场景的某个值，那aop统一处理显然就不合适（取不到特定情况的值），通用性强，意味着牺牲了特殊性的处理。
 仅限于记录通用的信息，比如入参，入参（返回值），异常信息等。不时候记录中间特殊的场景。
 四、错误的方式
 1、在catch中处理？

```php
catch (Exception e){
              logger.error("推送{失败 失败 error:-->{}, [ inParam]={}",e.getMessage(), inParam,e);
              logService.doExceptionLog(cacheInparamVO);
              throw  new BusinessException(e);
        }
```

显然doExceptionLog也是被回滚
 2、在finally处理？

```csharp
finally{
    logService.doFinallyLog(cacheInparamVO);
}
```

结果和catch处理一样。





##### 三、点击一个按钮，出现不动如何排查问题？



**「Q：10%的用户反馈用不了功能，你将如何排查？」**

关键词是`10%`，说明只对部分用户产生影响，考虑的思路有以下几点：

1. APP 版本影响，可能是接口改动没有考虑版本控制，对低版本用户造成影响。
2. 操作系统版本，可能是用户的操作系统过高或过低，没有做好兼容。
3. 灰度测试或 AB 测试，可能是功能缺陷导致对部分灰度用户产生影响。
4. 跟会员用户有关，可能是一些功能仅仅只对 VIP 会员开放，然而这部分功能有缺陷。
5. 跟用户分布地域有关，比如说：有些地区没有开放功能，但是也给这些用户展示了入口。



**「Q：登录的按钮不能点击，如何排查问题？」**

登录按钮不能点击，大概率前端会有问题：

1. 前端没有响应用户点击事件，导致请求发不出去。
2. 前端发起 HTTP 请求，但是后端接口返回异常，前端捕获异常之后，没有处理。
3. 网络异常，发不出去请求，但是前端也没有作出提示。
4. 内存不够，导致页面卡死







##### 四、单体服务同时点击，除了在service层加锁，如何在MySQL层面实现线程安全？

乐观锁假设认为数据一般情况下不会造成冲突，在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，拒绝操作。



##### 五、多对多的关系表如何设计？

解决方案：增加一张中间关系表
老师与学生的关系表：ID(P),T_ID,S_ID
老师表与中间表形成一对多的关系，而中间表是多表；维护了能够唯一找到一表的关系；
同样的学生表与中间表也是一个一对多的关系;



##### 六、MySQL如何实现去重？

1.使用distinct

2.delete from user where id not in ( select f.id from ((select id from user group by name order by id))f);





##### 七、SpringBoot的常用注解、自定义注解

##### 7.2、SpringBoot的核心注解是哪个？它主要由哪几个注解组成的？

启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：

@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。
@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能@SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。
@ComponentScan：Spring组件扫描。



##### 7.3、Spring Boot 自动配置原理是什么？

> 注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，首先它得是一个配置文件，其次根据类路径下是否有这个类去自动配置。

Spring Boot的自动配置注解是@EnableAutoConfiguration， 从上面的@Import的类可以找到下面自动加载自动配置的映射。

```java
 org.springframework.core.io.support.SpringFactoriesLoader.loadFactoryNames(Class<?>, ClassLoader)
```

```java
public static List<String> loadFactoryNames(Class<?> factoryClass, ClassLoader classLoader) {
  String factoryClassName = factoryClass.getName();
  try {
     Enumeration<URL> urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :
              lassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));
      List<String> result = new ArrayList<String>();
      while (urls.hasMoreElements()) {
          URL url = urls.nextElement();
          Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url));
          String factoryClassNames = properties.getProperty(factoryClassName);
          result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames)));
      }
      return result;
  }
  catch (IOException ex) {
      throw new IllegalArgumentException("Unable to load [" + factoryClass.getName() +
              "] factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex);
  }

}
```

这个方法会加载类路径及所有jar包下META-INF/spring.factories配置中映射的自动配置的类。

```java
/**
* The location to look for factories.
* <p>Can be present in multiple JAR files.
*/
public static final String FACTORIES_RESOURCE_LOCATION = "META-INF/spring.factories";
查看Spring Boot自带的自动配置的包： spring-boot-autoconfigure-1.5.6.RELEASE.jar，打开其中的META-INF/spring.factories文件会找到自动配置的映射。

org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\
org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\
org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\
org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\
org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\
org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\
...

```

再来看看数据源自动配置的实现注解

```java
@Configuration
@ConditionalOnClass({ DataSource.class, EmbeddedDatabaseType.class })
@EnableConfigurationProperties(DataSourceProperties.class)
@Import({ Registrar.class, DataSourcePoolMetadataProvidersConfiguration.class })
public class DataSourceAutoConfiguration {
...
@Configuration,@ConditionalOnClass就是自动配置的核心，首先它得是一个配置文件，其次根据类路径下是否有这个类去自动配置。
```



小结：

```txt
注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，

@EnableAutoConfiguration 给容器导入META-INF/spring.factories 里定义的自动配置类。

筛选有效的自动配置类。

每一个自动配置类结合对应的 xxxProperties.java 读取配置文件进行自动配置功能
```







##### 八、es相关





##### 九、6000万条数据、MySQL千万级别的，如何更快的找到某个用户某天的数据？





##### 十、Mongo和MySQL的区别，优势和缺点分别是？





##### 十一、ELK日志分析系统

![img](https://gitee.com/wmbyy/typora_pictures/raw/master/pictures/1932174-e517b43882e3c163.png)

Logstash是一个用来搜集、分析、过滤日志的工具，几乎支持所有类型的日志，能够接收多种来源的日志，包括syslog、mq，并且能够输出到多种介质中，包括es，邮件等等。

es是实时全文搜索和分析引擎，提供搜集、分析、存储数据三大功能，对外提供REST和java api，可扩展性的分布式系统。

Kibana是一个基于Web的图形界面，用于搜索、分析和可视化存储在 Elasticsearch指标中的日志数据。它利用Elasticsearch的REST接口来检索数据，不仅允许用户定制仪表板视图，还允许用户使用es语法进行操作。

但是，在实际使用的过程中发现，logstash会占用很多系统资源，因此决定加入一个更轻量的日志收集组件（也是elastic stack的组件之一）filebeat。因此在加入filebeat之后，整个部署架构变成了如下图所示。

![img](https://gitee.com/wmbyy/typora_pictures/raw/master/pictures/1932174-481ddef1355cdd9a.png)



##### 十二、分布式事务

CAP、BASE、2PC、3PC、TCC。



##### 十三、Feign的实现原理

Feign是一个http请求调用的轻量级框架，可以以Java接口注解的方式调用Http请求。Spring Cloud引入 Feign并且集成了Ribbon实现客户端负载均衡调用。

它封装了Http调用流程，更适合面向接口化的变成习惯。

远程调用步骤

```txt
1.基于面向接口的动态代理方式生成实现类，将请求调用委托到动态代理实现类
2.基于RequestBean,动态生成request
3.使用encoder将bean转换成http报文正文
4.拦截器负责对请求和返回进行装饰处理
5.发送可重试的HTTP请求
```



![img](https://gitee.com/wmbyy/typora_pictures/raw/master/pictures/6271376-7635e2dc9b32e3ec.png)



##### 十四：微服务网关Zuul和Gateway的区别

相同点

```txt
1、底层都是servlet

2、两者均是web网关，处理的是http请求
```

区别：

```txt
1、内部实现：
　　gateway对比zuul多依赖了spring-webflux，在spring的支持下，功能更强大，内部实现了限流、负载均衡等，扩展性也更强，但同时也限制了仅适合于Spring Cloud套件
　　zuul则可以扩展至其他微服务框架中，其内部没有实现限流、负载均衡等。
2、是否支持异步
　　zuul仅支持同步
　　gateway支持异步。
3、框架设计的角度
　　gateway具有更好的扩展性，并且其已经发布了2.0.0的RELESE版本，稳定性也是非常好的
4、性能
	gateway使用了WebFlux，来构建异步的、非堵塞的服务
	Zuul 1.x，是一个基于阻塞io的API Gateway,zuul2.x基于netty，也是非阻塞的，支持长连接的，但没有被spring cloud整合
```

##### 十五、Nacos与Eureka区别

相同点：

```txt
注册中心、健康检查、负载均衡、
```

仅Nacos支持的

```txt
配置中心、动态刷新、分组、流量控制、管理界面
```



##### 十六、Autowried原理

```txt
工作原理
 注解解析器：AutowiredAnnotationBeanPostProcessor

Spring容器启动时，AutowiredAnnotationBeanPostProcessor被注册到容器；
扫描代码，如果带有@Autowired注解，则将依赖注入信息封装到InjectionMetadata中；
创建bean时（实例化对象和初始化），会调用各种BeanPostProcessor对bean初始化，AutowiredAnnotationBeanPostProcessor的postProcessPropertyValues方法负责将相关的依赖注入进来；

```

##### 十七、消息队列

我们可以把消息队列看作是一个存放消息的容器，当我们需要使用消息的时候，直接从容器中取出消息供自己使用即可。

优势

```txt
通过异步处理提高系统性能（减少响应所需时间）。
削峰/限流： 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。
降低系统耦合性：对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计。
```

缺点

```txt
系统可用性降低： 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！
系统复杂性提高： 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！
一致性问题： 消息的真正消费者并没有正确消费消息就会导致数据不一致的情况了
```

##### 十八、Kafka 如何保证消息的消费顺序？

![img](https://gitee.com/wmbyy/typora_pictures/raw/master/pictures/KafkaTopicPartionsLayout.png)

每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。 **Kafka 只能为我们保证 Partition(分区) 中的消息有序。**

> 消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。

```txt
1. 1 个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key、Partition。Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数
```



##### 十九、Kafka 如何保证消息不丢失

###### 生产者丢失消息的情况

```txt
1.Kafka 生产者(Producer) 使用 send 方法发送消息实际上是异步的操作，为了确定消息是发送成功，我们要判断消息发送的结果，以采用为其添加回调函数的形式。
2.采用重试机制，retries （重试次数）设置一个比较合理的值，一般是 3。
```



###### Kafka 弄丢了消息

```txt
Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。


设置 acks = all， 
解决办法就是我们设置 acks = all。acks 是 Kafka 生产者(Producer) 很重要的一个参数。
当我们配置 acks = all 代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。acks 的默认值即为1，代表我们的消息被leader副本接收之后就算被成功发送。

设置 replication.factor >= 3
为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 replication.factor >= 3。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。

设置 min.insync.replicas > 1
一般情况下我们还需要设置 min.insync.replicas> 1 ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。min.insync.replicas 的默认值为 1 ，在实际生产中应尽量避免默认值 1。

设置 unclean.leader.election.enable = false
当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。


```

###### 消费者丢失消息的情况

```txt
手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset。这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。
```



##### 二十、Kafka 如何保证消息不重复消费

###### 出现原因

```txt
服务端侧已经消费的数据没有成功提交offset（根本原因）。
Kafka 侧由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。
```

###### 解决方案

```txt
消费消息服务做幂等校验，比如 Redis 的set、MySQL 的主键等天然的幂等功能。这种方法最有效。
将 enable.auto.commit 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：什么时候提交offset合适？
	处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
	拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。
```





##### 二十一、一条SQL语句是如何执行的

###### 查询语句的执行步骤

- 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。
- 通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 ，需要查询所有的列，查询条件。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
- 接下来就是优化器进行确定执行方案，那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。
- 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。

###### 更新语句的执行步骤

- 先查询到这一条数据，如果有缓存，也是会用到缓存。
- 然后拿到查询的语句，，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。
- 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。
- 更新完成。





